{
    "title": "Title",
    "author": "USP",
    "body": "Redes Neurais Artificiais\n\nVoc\u00ea\nver\u00e1 nesta p\u00e1gina um tutorial introdut\u00f3rio sobre Redes\nNeurais Artificiais, em especial sobre as Redes Multi Layer Perceptron treinadas\ncom BackPropagation\n\nT\u00f3picos:\n\nIntrodu\u00e7\u00e3o\n\nUm Breve Hist\u00f3rico Caracter\u00edsticas\nGerais das Redes Neurais Processos de Aprendizado Treinamento Supervisionado\n\nPerceptron\nmulti-camadas (MLP)\n\nBackpropagation\nTreinamento da Rede MLP\nUtiliza\u00e7\u00e3o\nLimita\u00e7\u00f5es\n\nDesenvolvimento\nde Aplica\u00e7\u00f5es\n\nHot\nLinks\n\nIntrodu\u00e7\u00e3o\n\nRedes Neurais Artificiais s\u00e3o t\u00e9cnicas computacionais que apresentam\num modelo matem\u00e1tico inspirado na estrutura neural de organismos inteligentes\ne que adquirem conhecimento atrav\u00e9s da experi\u00eancia. Uma grande\nrede neural artificial pode ter centenas ou milhares de unidades de processamento;\nj\u00e1 o c\u00e9rebro de um mam\u00edfero pode ter muitos bilh\u00f5es\nde neur\u00f4nios.\n\nO sistema nervoso \u00e9 formado\npor um conjunto extremamente complexo de c\u00e9lulas, os neur\u00f4nios.\nEles t\u00eam um papel essencial na determina\u00e7\u00e3o do funcionamento\ne comportamento do corpo humano e do racioc\u00ednio. Os neur\u00f4nios s\u00e3o\nformados pelos dendritos, que s\u00e3o um conjunto de terminais de entrada,\npelo corpo central, e pelos ax\u00f4nios que s\u00e3o longos terminais de\nsa\u00edda.\n\nConstitu\u00edntes da\nc\u00e9lula neuronal - esquema.\n\nOutras figura:\n\nCortex - esquema.\n\nV\u00e1rias formas de neur\u00f4nios - esquema.\n\nMicro-fotografia de neur\u00f4nios 1.\n\nMicro-fotografia de neur\u00f4nios 2.\n\nMicro-fotografia de neur\u00f4nio de macaco.\n\nMicro-fotografia de neur\u00f4nios em sinapse.\n\nOs neur\u00f4nios se comunicam\natrav\u00e9s de sinapses. Sinapse \u00e9 a regi\u00e3o onde dois neur\u00f4nios\nentram em contato e atrav\u00e9s da qual os impulsos nervosos s\u00e3o transmitidos\nentre eles. Os impulsos recebidos por um neur\u00f4nio A, em um determinado\nmomento, s\u00e3o processados, e atingindo um dado limiar de a\u00e7\u00e3o,\no neur\u00f4nio A dispara, produzindo uma subst\u00e2ncia neurotransmissora\nque flui do corpo celular para o ax\u00f4nio, que pode estar conectado a um\ndendrito de um outro neur\u00f4nio B. O neurotransmissor pode diminuir ou aumentar\na polaridade da membrana p\u00f3s-sin\u00e1ptica, inibindo ou excitando\na gera\u00e7\u00e3o dos pulsos no neur\u00f4nio B. Este processo depende\nde v\u00e1rios fatores, como a geometria da sinapse e o tipo de neurotransmissor.\n\nEm m\u00e9dia, cada neur\u00f4nio\nforma entre mil e dez mil sinapses. O c\u00e9rebro humano possui cerca de\n10 E11 neur\u00f4nios, e o n\u00famero de sinapses \u00e9 de mais de 10\nE14, possibilitando a forma\u00e7\u00e3o de redes muito complexa.\n\nUm Breve Hist\u00f3rico\n\nUm hist\u00f3rico resumido sobre Redes Neurais Artificiais deve come\u00e7ar\npor tr\u00eas das mais importantes publica\u00e7\u00f5es iniciais, desenvolvidas\npor: McCulloch e Pitts (1943), Hebb (1949), e Rosemblatt (1958). Estas publica\u00e7\u00f5es\nintroduziram o primeiro modelo de redes neurais simulando \u0093m\u00e1quinas\u0094,\no modelo b\u00e1sico de rede de auto-organiza\u00e7\u00e3o, e o modelo\nPerceptron de aprendizado supervisionado, respectivamente.\n\nAlguns hist\u00f3ricos sobre\na \u00e1rea costumam \u0093pular\u0094 os anos 60 e 70 e apontar um re\u00ednicio\nda \u00e1rea com a publica\u00e7\u00e3o dos trabalhos de Hopfield (1982)\nrelatando a utiliza\u00e7\u00e3o de redes sim\u00e9tricas para otimiza\u00e7\u00e3o\ne de Rumelhart, Hinton e Williams que introduziram o poderoso m\u00e9todo\nBackpropagation.\n\nEntretanto, para se ter um hist\u00f3rico\ncompleto, devem ser citados alguns pesquisadores que realizaram, nos anos 60\ne 70, importantes trabalhos sobre modelos de redes neurais em vis\u00e3o,\nmem\u00f3ria, controle e auto-organiza\u00e7\u00e3o como: Amari, Anderson,\nCooper, Cowan, Fukushima, Grossberg, Kohonen, von der Malsburg, Werbos e Widrow.\n\nCaracter\u00edsticas Gerais das Redes Neurais\n\nUma rede neural artificial \u00e9 composta por v\u00e1rias unidades de processamento,\ncujo funcionamento \u00e9 bastante simples. Essas unidades, geralmente s\u00e3o\nconectadas por canais de comunica\u00e7\u00e3o que est\u00e3o associados\na determinado peso. As unidades fazem opera\u00e7\u00f5es apenas sobre seus\ndados locais, que s\u00e3o entradas recebidas pelas suas conex\u00f5es.\nO comportamento inteligente de uma Rede Neural Artificial vem das intera\u00e7\u00f5es\nentre as unidades de processamento da rede.\n\nA opera\u00e7\u00e3o de uma\nunidade de processamento, proposta por McCullock e Pitts em 1943, pode ser resumida\nda seguinte maneira:\n\n* Sinais s\u00e3o apresentados \u00e0\nentrada;\n* Cada sinal \u00e9 multiplicado por um\nn\u00famero, ou peso, que indica a sua influ\u00eancia na sa\u00edda\nda unidade;\n* \u00c9 feita a soma ponderada dos sinais\nque produz um n\u00edvel de atividade;\n* Se este n\u00edvel de atividade exceder\num certo limite (threshold) a unidade produz uma determinada resposta de\nsa\u00edda.\n\nEsquema de unidade McCullock\n- Pitts.\n\nSuponha que tenhamos p sinais\nde entrada X1, X2, ..., Xp e pesos w1, w2, ..., wp e limitador t; com sinais\nassumindo valores booleanos (0 ou 1) e pesos valores reais.\n\nNeste modelo, o n\u00edvel\nde atividade a \u00e9 dado por:\n\na = w1X1 + w2X2 + ... + wpXp\n\nA sa\u00edda y \u00e9 dada\npo\n\ny = 1, se a >=\nt ou\n\ny = 0, se a <\nt.\n\nA maioria dos modelos de redes neurais possui\nalguma regra de treinamento, onde os pesos de suas conex\u00f5es s\u00e3o\najustados de acordo com os padr\u00f5es apresentados. Em outras palavras,\nelas aprendem atrav\u00e9s de exemplos.\n\nArquiteturas neurais s\u00e3o\ntipicamente organizadas em camadas, com unidades que podem estar conectadas\n\u00e0s unidades da camada posterior.\n\nOrganiza\u00e7\u00e3o\nem camadas.\n\nUsualmente as camadas s\u00e3o\nclassificadas em tr\u00eas grupos:\n\n* Camada de Entrada: onde os padr\u00f5es\ns\u00e3o apresentados \u00e0 rede;\n* Camadas Intermedi\u00e1rias ou Escondidas:\nonde \u00e9 feita a maior parte do processamento, atrav\u00e9s das conex\u00f5es\nponderadas; podem ser consideradas como extratoras de caracter\u00edsticas;\n* Camada de Sa\u00edda: onde o resultado\nfinal \u00e9 conclu\u00eddo e apresentado.\n\nUma rede neural \u00e9 especificada,\nprincipalmente pela sua topologia, pelas caracter\u00edsticas dos n\u00f3s\ne pelas regras de treinamento. A seguir, ser\u00e3o analisados os processos\nde aprendizado.\n\nProcessos de Aprendizado\n\nA propriedade mais importante das redes neurais \u00e9 a habilidade de aprender\nde seu ambiente e com isso melhorar seu desempenho. Isso \u00e9 feito atrav\u00e9s\nde um processo iterativo de ajustes aplicado a seus pesos, o treinamento. O\naprendizado ocorre quando a rede neural atinge uma solu\u00e7\u00e3o generalizada\npara uma classe de problemas.\n\nDenomina-se algoritmo de aprendizado a um conjunto\nde regras bem definidas para a solu\u00e7\u00e3o de um problema de aprendizado.\nExistem muitos tipos de algoritmos de aprendizado espec\u00edficos para determinados\nmodelos de redes neurais, estes algoritmos diferem entre si principalmente pelo\nmodo como os pesos s\u00e3o modificados.\n\nOutro fator importante \u00e9 a maneira pela\nqual uma rede neural se relaciona com o ambiente. Nesse contexto existem os\nseguintes paradigmas de aprendizado:\n\n* Aprendizado Supervisionado, quando\n\u00e9 utilizado um agente externo que indica \u00e0 rede a resposta\ndesejada para o padr\u00e3o de entrada;\n* Aprendizado N\u00e3o Supervisionado\n(auto-organiza\u00e7\u00e3o), quando n\u00e3o existe uma agente externo\nindicando a resposta desejada para os padr\u00f5es de entrada;\n* Refor\u00e7o, quando um cr\u00edtico\nexterno avalia a resposta fornecida pela rede.\n\nDenomina-se ciclo uma apresenta\u00e7\u00e3o\nde todos os N pares (entrada e sa\u00edda) do conjunto de treinamento no processo\nde aprendizado. A corre\u00e7\u00e3o dos pesos num ciclo pode ser executado\nde dois modos:\n\n1) Modo Padr\u00e3o:\nA corre\u00e7\u00e3o dos pesos acontece a cada apresenta\u00e7\u00e3o\n\u00e0 rede de um exemplo do conjunto de treinamento. Cada corre\u00e7\u00e3o\nde pesos baseia-se somente no erro do exemplo apresentado naquela itera\u00e7\u00e3o.\nAssim, em cada ciclo ocorrem N corre\u00e7\u00f5es.\n\n2) Modo Batch: Apenas\numa corre\u00e7\u00e3o \u00e9 feita por ciclo. Todos os exemplos do\nconjunto de treinamento s\u00e3o apresentados \u00e0 rede, seu erro m\u00e9dio\n\u00e9 calculado e a partir deste erro fazem-se as corre\u00e7\u00f5es\ndos pesos.\n\nTreinamento Supervisionado\n\nO treinamento supervisionado do modelo de rede Perceptron, consiste em ajustar\nos pesos e os thresholds de suas unidades para que a classifica\u00e7\u00e3o\ndesejada seja obtida. Para a adapta\u00e7\u00e3o do threshold juntamente\ncom os pesos podemos consider\u00e1-lo como sendo o peso associado a uma conex\u00e3o,\ncuja entrada \u00e9 sempre igual \u00e0 -1 e adaptar o peso relativo a essa\nentrada.\n\nQuando um padr\u00e3o \u00e9 inicialmente\napresentado \u00e0 rede, ela produz uma sa\u00edda. Ap\u00f3s medir a\ndist\u00e2ncia entre a resposta atual e a desejada, s\u00e3o realizados os\najustes apropriados nos pesos das conex\u00f5es de modo a reduzir esta dist\u00e2ncia.Este\nprocedimento \u00e9 conhecido como Regra Delta.\n\nRegra Delta\n\nDeste modo, temos o seguinte\nesquema de treinamento.\n\nIniciar todas as conex\u00f5es com pesos\naleat\u00f3rios;\n\nRepita at\u00e9 que o erro E seja satisfatoriamente\npequeno (E = e)\n\nPara cada par de treinamento (X,d), fa\u00e7a:\n\nCalcular a resposta obtida O;\n\nSe o erro n\u00e3o for satisfatoriamente\npequeno E > e, ent\u00e3o:\n\nAtualizar pesos: Wnovo := W anterior + neta\nE X\n\nOnde:\n\n* O par de treinamento (X, d) corresponde\nao padr\u00e3o de entrada e a sua respectiva resposta desejada;\n* O erro E \u00e9 definido como: Resposta\nDesejada - Resposta Obtida (d - O);\n* A taxa de aprendizado neta \u00e9 uma\nconstante positiva, que corresponde \u00e0 velocidade do aprendizado.\n\nEsquema de treinamento do\nPerceptron.\n\nAs respostas geradas pelas unidades\ns\u00e3o calculadas atrav\u00e9s de uma fun\u00e7\u00e3o de ativa\u00e7\u00e3o.\nExistem v\u00e1rios tipos de fun\u00e7\u00f5es de ativa\u00e7\u00e3o,\nas mais comuns s\u00e3o: Hard Limiter, Threshold Logic e Sigmoid.\n\nT\u00f3picos\nPerceptron\nMulti-Camadas (MLP)\nDesenvolvimento\nde Aplica\u00e7\u00f5es\n\nHot Links\n\nLinks\npara p\u00e1ginas sobre Redes Neurais Artificiais.\n\nSNNS- Sttutgart\nNeural Networks Simulator.\n\nBack to my personal page!",
    "type": "article",
    "url": "https://sites.icmc.usp.br/andre/research/neural/"
}