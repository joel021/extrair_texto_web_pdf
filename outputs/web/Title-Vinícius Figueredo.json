{
    "title": "Title",
    "author": "VinÃ­cius Figueredo",
    "body": "Seus primeiros passos como Data Scientist: Introdu\u00e7\u00e3o ao Pandas! | by Vin\u00edcius Figueiredo | Data Hackers | Medium\n\nSign in\n\n* \u00daltimos posts\n* Engenharia\n* Ci\u00eancia\n* ML\n* Podcast\n* Escreva no DH\n* CONHE\u00c7A O DATA HACKERS!\n\nResponses\n\nSeus primeiros passos como Data Scientist: Introdu\u00e7\u00e3o ao Pandas!\n\nVin\u00edcius Figueiredo\nFollow\n\nMay 30, 2018 \u00b7 12 min read\n\nPhoto by Chester Ho on Unsplash\n\nAl\u00e9m desses animaizinhos simp\u00e1ticos, Pandas tamb\u00e9m \u00e9 uma biblioteca Python. Ela fornece ferramentas de an\u00e1lise de dados e estruturas de dados de alta performance e f\u00e1ceis de usar.\n\nPor ser a principal e mais completa biblioteca para estes objetivos, Pandas \u00e9 fundamental para An\u00e1lise de Dados.\n\nDisclaimer\n\nEsse guia foi escrito como uma alternativa em portugu\u00eas \u00e0s introdu\u00e7\u00f5es j\u00e1 existentes e \u00e0 introdu\u00e7\u00e3o de 10 minutos apresentada na documenta\u00e7\u00e3o oficial, e tem por objetivo fornecer de forma enxuta e simplificada uma apresenta\u00e7\u00e3o b\u00e1sica \u00e0s principais ferramentas fornecidas pelo pandas, cobrindo:\n\n* Manipula\u00e7\u00e3o,\n* Leitura,\n* Visualiza\u00e7\u00e3o de dados.\n\nA introdu\u00e7\u00e3o pressup\u00f5e apenas conhecimento b\u00e1sico em Python.\n\nComo o Medium n\u00e3o disponibiliza highlight de sintaxe para gente, h\u00e1 duas outras excelentes op\u00e7\u00f5es de acessar esta introdu\u00e7\u00e3o:\n\n* Voc\u00ea pode acessar o MyBinder deste arquivo, que cria um ambiente interativo Jupyter rodando Python com todas as depend\u00eancias necess\u00e1rias automaticamente, onde voc\u00ea pode testar e executar por si mesmo as linhas de c\u00f3digo deste tutorial direto do seu navegador sem precisar configurar nada.\n* Voc\u00ea pode acessar o notebook viewer deste arquivo, que fornece syntax highlighting e formata\u00e7\u00e3o mais padronizada com o que se est\u00e1 acostumado num notebook Jupyter.\n\nM\u00e3os \u00e0 obra!\n\nVamos come\u00e7ar com as importa\u00e7\u00f5es, usaremos al\u00e9m do pandas, o numpy, biblioteca para computa\u00e7\u00e3o cient\u00edfica e o matplotlib, biblioteca principal para visualiza\u00e7\u00e3o de dados, entretanto, como veremos mais adiante, o pr\u00f3prio pandas nos fornece facilidades em rela\u00e7\u00e3o \u00e0 visualiza\u00e7\u00e3o de dados, com m\u00e9todos constru\u00eddos com base no matplotlib, tamb\u00e9m importamos esta biblioteca para, al\u00e9m de poder modificar esteticamente nossos gr\u00e1ficos, facilitar a exibi\u00e7\u00e3o dos gr\u00e1ficos. A linha\n%matplotlib inline\n\nfaz parte da m\u00e1gica do Jupyter e voc\u00ea n\u00e3o deve rod\u00e1-la caso esteja em outra IDE/Ambiente.\n\nimport pandas as pd\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\nExistem dois tipos principais de estruturas de dados no pandas:\n\nSeries\n\nUma Series \u00e9 como um array unidimensional, uma lista de valores. Toda Series possui um \u00edndice, o\nindex\n\n, que d\u00e1 r\u00f3tulos a cada elemento da lista. Abaixo criamos uma Series\nnotas\n\n, o\nindex\n\ndesta Series \u00e9 a coluna \u00e0 esquerda, que vai de 0 a 4 neste caso, que o pandas criou automaticamente, j\u00e1 que n\u00e3o especificamos uma lista de r\u00f3tulos.\n\nnotas = pd.Series([2,7,5,10,6])\n\nnotas0 2\n\n1 7\n\n2 5\n\n3 10\n\n4 6\n\ndtype: int64\n\nJ\u00e1 podemos aqui verificar os atributos da nossa Series, comecemos pelos valores e o \u00edndice, os dois atributos fundamentais nesta estrutura:\n\nnotas.valuesarray([ 2, 7, 5, 10, 6])notas.indexRangeIndex(start=0, stop=5, step=1)\n\nComo ao criar a Series n\u00e3o demos um \u00edndice espec\u00edfico o pandas usou os inteiros positivos crescentes como padr\u00e3o. Pode ser conveniente atribuirmos um \u00edndice diferente do padr\u00e3o, supondo que essas sejam notas de uma turma, poder\u00edamos atribuir nomes ao index:\n\nnotas = pd.Series([2,7,5,10,6], index=[\"Wilfred\", \"Abbie\", \"Harry\", \"Julia\", \"Carrie\"])\n\nnotasWilfred 2\n\nAbbie 7\n\nHarry 5\n\nJulia 10\n\nCarrie 6\n\ndtype: int64\n\nO index nos ajuda para referenciar um determinado valor, ele nos permite acessar os valores pelo seu r\u00f3tulo:\n\nnotas[\"Julia\"]10\n\nOutra facilidade proporcionada pela estrutura s\u00e3o seus m\u00e9todos que fornecem informa\u00e7\u00f5es estat\u00edsticas sobre os valores, como m\u00e9dia\n.mean()\n\ne desvio padr\u00e3o\n.std()\n\n. Encorajo o leitor(a) a investigar e verificar alguns dos m\u00e9todos e atributos da estrutura usando o\nTAB\n\npara auto-completa\u00e7\u00e3o na shell do Python, ou simplesmente checar a complet\u00edssima documenta\u00e7\u00e3o oficial deste objeto.\n\nprint(\"M\u00e9dia:\", notas.mean())\n\nprint(\"Desvio padr\u00e3o:\", notas.std())M\u00e9dia: 6.0\n\nDesvio padr\u00e3o: 2.9154759474226504\n\nGeralmente para resumir brevemente as estat\u00edsticas dos dados se usa o\n.describe()\n\nnotas.describe()count 5.000000\n\nmean 6.000000\n\nstd 2.915476\n\nmin 2.000000\n\n25% 5.000000\n\n50% 6.000000\n\n75% 7.000000\n\nmax 10.000000\n\ndtype: float64\n\nA estrutura \u00e9 flex\u00edvel o suficiente pra aplicarmos algumas express\u00f5es matem\u00e1ticas e fun\u00e7\u00f5es matem\u00e1ticas do numpy diretamente:\n\nnotas**2Wilfred 4\n\nAbbie 49\n\nHarry 25\n\nJulia 100\n\nCarrie 36\n\ndtype: int64np.log(notas)Wilfred 0.693147\n\nAbbie 1.945910\n\nHarry 1.609438\n\nJulia 2.302585\n\nCarrie 1.791759\n\ndtype: float64\n\nDataFrame\n\nJ\u00e1 um DataFrame \u00e9 uma estrutura bidimensional de dados, como uma planilha. Abaixo criaremos um DataFrame que possui valores de diferentes tipos, usando um dicion\u00e1rio como entrada dos dados:\n\ndf = pd.DataFrame({'Aluno' : [\"Wilfred\", \"Abbie\", \"Harry\", \"Julia\", \"Carrie\"],\n\n'Faltas' : [3,4,2,1,4],\n\n'Prova' : [2,7,5,10,6],\n\n'Semin\u00e1rio': [8.5,7.5,9.0,7.5,8.0]})\n\ndf\n\nOs tipos de dados que comp\u00f5e as colunas podem ser verificados por um m\u00e9todo pr\u00f3prio:\n\ndf.dtypesAluno object\n\nFaltas int64\n\nProva int64\n\nSemin\u00e1rio float64\n\ndtype: object\n\n\u00c9 poss\u00edvel acessar a lista de colunas de forma bem intuitiva:\n\ndf.columnsIndex(['Aluno', 'Faltas', 'Prova', 'Semin\u00e1rio'], dtype='object')\n\nOs nomes das colunas podem ser usadas pra acessar seus valores:\n\ndf[\"Semin\u00e1rio\"]0 8.5\n\n1 7.5\n\n2 9.0\n\n3 7.5\n\n4 8.0\n\nName: Semin\u00e1rio, dtype: float64\n\nPara DataFrames,\n.describe()\n\ntamb\u00e9m \u00e9 uma boa forma de verificar resumidamente a disposi\u00e7\u00e3o estat\u00edstica dos dados num\u00e9ricos:\n\ndf.describe()\n\nOutra tarefa comum aplicada em DataFrames \u00e9 orden\u00e1-los por determinada coluna:\n\ndf.sort_values(by=\"Semin\u00e1rio\")\n\nNote que simplesmente usar o m\u00e9todo\nsort_values\n\nn\u00e3o modifica o nosso DataFrame original:\n\ndf\n\nMuitas vezes \u00e9 necess\u00e1rio selecionarmos valores espec\u00edficos de um DataFrame, seja uma linha ou uma c\u00e9lula espec\u00edfica, e isso pode ser feito de diversas formas. A documenta\u00e7\u00e3o oficial cont\u00e9m vasta informa\u00e7\u00e3o para esse tipo de tarefa, aqui nos concentraremos nas formas mais comuns de selecionarmos dados.\n\nPara selecionar pelo index ou r\u00f3tulo usamos o atributo\n.loc\n\n:\n\ndf.loc[3]Aluno Julia\n\nFaltas 1\n\nProva 10\n\nSemin\u00e1rio 7.5\n\nName: 3, dtype: object\n\nPara selecionar de acordo com crit\u00e9rios condicionais, se usa o que se chama de Boolean Indexing.\n\nSuponha que queiramos selecionar apenas as linhas em que o valor da coluna Semin\u00e1rio seja acima de 8.0, podemos realizar esta tarefa passando a condi\u00e7\u00e3o diretamente como \u00edndice:\n\ndf[df[\"Semin\u00e1rio\"] > 8.0]\n\nEste tipo de indexa\u00e7\u00e3o tamb\u00e9m possibilita checar condi\u00e7\u00f5es de m\u00faltiplas colunas. Diferentemente do que estamos habituados em Python, aqui se usam operadores bitwise, ou seja,\n&\n\n,\n|\n\n,\n~\n\nao inv\u00e9s de\nand\n\n,\nor\n\n,\nnot\n\n, respectivamente. Suponha que al\u00e9m de\ndf[\"Semin\u00e1rio\"] > 8.0\n\nqueiramos que o valor da coluna\nProva\n\nn\u00e3o seja menor que 3:\n\ndf[(df[\"Semin\u00e1rio\"] > 8.0) & (df[\"Prova\"] > 3)]\n\nPor enquanto \u00e9 isso para manipula\u00e7\u00e3o de Series e DataFrames, conforme a se\u00e7\u00e3o de leitura de dados for se estendendo irei aprensentar alguns outros m\u00e9todos dessas estruturas que poder\u00e3o ser interessantes no contexto.\n\nLeitura de Dados\n\nNa se\u00e7\u00e3o anterior vimos como manipular dados que foram criados durante esta apresenta\u00e7\u00e3o, acontece que, na maioria das vezes, queremos analisar dados que j\u00e1 est\u00e3o prontos. O pandas nos fornece uma s\u00e9rie de funcionalidades de leitura de dados, pros mais diversos formatos estruturais de dados, experimente a auto-completa\u00e7\u00e3o de\npd.read_<TAB>\n\n, entre eles est\u00e3o:\n\n*\npd.read_csv\n\n, para ler arquivos .csv, formato comum de armazenar dados de tabelas\n*\npd.read_xlsx\n\n, para ler arquivos Excel .xlsx, \u00e9 necess\u00e1rio instalar uma biblioteca adicional pra esta funcionalidade.\n*\npd.read_html\n\n, para ler tabelas diretamente de um website\n\nUsaremos para analisar dados externos nesta introdu\u00e7\u00e3o o\n.read_csv\n\n, pois \u00e9 neste formato que se encontram nossos dados. CSV, ou comma-separated values \u00e9 um formato muito comum de dados abertos, trata-se, como a sigla sugere, de valores divididos por v\u00edrgula, apesar de o caracter separador poder ser o ponto-e-v\u00edrgula ou outro.\n\nO arquivo\ndados.csv\n\nest\u00e1 na mesma pasta do nosso script, ent\u00e3o podemos passar como argumento do\n.read_csv\n\napenas o seu nome. Outro argumento interessante da fun\u00e7\u00e3o \u00e9 o\nsep\n\n, que por padr\u00e3o \u00e9 a v\u00edrgula, mas que pode ser definido como outro caractere caso seu dado esteja usando outro separador.\n\nEstes dados que usaremos como exemplo s\u00e3o dados sobre pre\u00e7os de apartamentos em 7 bairros da cidade do Rio de Janeiro: Botafogo, Copacabana, G\u00e1vea, Graja\u00fa, Ipanema, Leblon, Tijuca. Os dados podem ser encontrados aqui (Basta baixar diretamente ou copiar o texto pro seu editor preferido e salvar como dados.csv).\n\ndf = pd.read_csv(\"dados.csv\")\n\ndf\n\nComo esperado, o DataFrame tem muitas linhas de dados, pra visualizar sucintamente as primeiras linhas de um DataFrame existe o m\u00e9todo\n.head()\n\ndf.head()\n\nPor padr\u00e3o\n.head()\n\nexibe as 5 primeiras linhas, mas isso pode ser alterado:\n\ndf.head(n=10)\n\nSimilarmente existe o\n.tail()\n\n, que exibe por padr\u00e3o as \u00faltimas 5 linhas do DataFrame:\n\ndf.tail()\n\nManipula\u00e7\u00e3o de Dados\n\nAl\u00e9m de confiar em mim, quando mencionei os bairros que continham no nosso conjunto de dados, voc\u00ea pode verificar a informa\u00e7\u00e3o usando um m\u00e9todo que lista os valores \u00fanicos numa coluna:\n\ndf[\"bairro\"].unique()array(['Botafogo', 'Copacabana', 'G\u00e1vea', 'Graja\u00fa', 'Ipanema', 'Leblon',\n\n'Tijuca'], dtype=object)\n\nTamb\u00e9m parece interessante verificarmos a hegemoneidade da nossa amostra em rela\u00e7\u00e3o aos bairros. Pra tarefas de contar valores podemos sempre aproveitar de outro m\u00e9todo dispon\u00edvel, o\n.value_counts()\n\n, tamb\u00e9m veremos um pouco mais abaixo como visualizar estes valores em forma de gr\u00e1fico de barras.\n\ndf[\"bairro\"].value_counts()Copacabana 346\n\nTijuca 341\n\nBotafogo 307\n\nIpanema 281\n\nLeblon 280\n\nGraja\u00fa 237\n\nG\u00e1vea 205\n\nName: bairro, dtype: int64\n\nOs valores contados tamb\u00e9m podem ser normalizados para expressar porcentagens:\n\ndf[\"bairro\"].value_counts(normalize=True)Copacabana 0.173260\n\nTijuca 0.170756\n\nBotafogo 0.153731\n\nIpanema 0.140711\n\nLeblon 0.140210\n\nGraja\u00fa 0.118678\n\nG\u00e1vea 0.102654\n\nName: bairro, dtype: float64\n\nAgrupar os dados se baseando em certos crit\u00e9rios \u00e9 outro processo que o pandas facilita bastante com o\n.groupby()\n\n. Esse m\u00e9todo pode ser usado para resolver os mais amplos dos problemas, aqui abordarei apenas o agrupamento simples, a divis\u00e3o de um DataFrame em grupos.\n\nAbaixo agrupamos o nosso DataFrame pelos valores da coluna\n\"bairro\"\n\n, e em seguida aplicamos o\n.mean()\n\npara termos um objeto GroupBy com informa\u00e7\u00e3o das m\u00e9dias agrupadas pelos valores da coluna bairros.\n\ndf.groupby(\"bairro\").mean()\n\nPara extrairmos dados de uma coluna deste objeto basta acess\u00e1-lo convencionalmente, para obtermos os valores da m\u00e9dia do pre\u00e7o do metro quadrado em ordem crescente, por exemplo:\n\ndf.groupby(\"bairro\").mean()[\"pm2\"].sort_values()bairro\n\nGraja\u00fa 6145.624473\n\nTijuca 7149.804985\n\nCopacabana 11965.298699\n\nBotafogo 12034.486189\n\nG\u00e1vea 16511.582780\n\nIpanema 19738.407794\n\nLeblon 20761.351036\n\nName: pm2, dtype: float64\n\n\u00c9 comum queremos aplicar uma fun\u00e7\u00e3o qualquer aos dados, ou \u00e0 parte deles, neste caso o pandas fornece o m\u00e9todo\n.apply\n\n. Por exemplo, para deixar os nomes dos bairros como apenas as suas tr\u00eas primeiras letras:\n\ndef truncar(bairro):\n\nreturn bairro[:3]df[\"bairro\"].apply(truncar)0 Bot\n\n1 Bot\n\n2 Bot\n\n3 Bot\n\n4 Bot\n\n5 Bot\n\n6 Bot\n\n7 Bot\n\n8 Bot\n\n9 Bot\n\n10 Bot\n\n...\n\n1987 Tij\n\n1988 Tij\n\n1989 Tij\n\n1990 Tij\n\n1991 Tij\n\n1992 Tij\n\n1993 Tij\n\n1994 Tij\n\n1995 Tij\n\n1996 Tij\n\nName: bairro, Length: 1997, dtype: object\n\nOu de um jeito mais pr\u00e1tico, usando uma fun\u00e7\u00e3o lambda:\n\ndf[\"bairro\"].apply(lambda x: x[:3])0 Bot\n\n1 Bot\n\n2 Bot\n\n3 Bot\n\n4 Bot\n\n5 Bot\n\n6 Bot\n\n7 Bot\n\n8 Bot\n\n9 Bot\n\n10 Bot\n\n...\n\n1986 Tij\n\n1987 Tij\n\n1988 Tij\n\n1989 Tij\n\n1990 Tij\n\n1991 Tij\n\n1992 Tij\n\n1993 Tij\n\n1994 Tij\n\n1995 Tij\n\n1996 Tij\n\nName: bairro, Length: 1997, dtype: object\n\nUma das tarefas na qual o pandas \u00e9 reconhecidamente poderoso \u00e9 a habilidade de tratar dados incompletos. Por muitos motivos pode haver incompletude no dataset, o\nnp.nan\n\n\u00e9 um valor especial definido no Numpy, sigla para Not a Number, o pandas preenche c\u00e9lulas sem valores em um DataFrame lido com\nnp.nan\n\n.\n\nVamos criar um novo dataframe usando as 5 primeiras linhas do nosso original, usando o j\u00e1 visto\n.head()\n\n. Abaixo \u00e9 usado o\n.replace\n\npara substituir um valor espec\u00edfico por um\nNaN\n\n.\n\ndf2 = df.head()\n\ndf2 = df2.replace({\"pm2\": {12031.25: np.nan}})\n\ndf2\n\nO pandas simplifica a remo\u00e7\u00e3o de quaiquer linhas ou colunas que possuem um\nnp.nan\n\n, por padr\u00e3o o\n.dropna()\n\nretorna as linhas que n\u00e3o cont\u00e9m um NaN:\n\ndf2.dropna()\n\nPreencher todos os valores NaN por um outro espec\u00edfico tamb\u00e9m \u00e9 bastante simples:\n\ndf2.fillna(99)\n\nAcaba sendo muitas vezes conveniente termos um m\u00e9todo que indica quais valores de um dataframe s\u00e3o NaN e quais n\u00e3o s\u00e3o:\n\ndf2.isna()\n\nVisualiza\u00e7\u00e3o de Dados\n\nPartiremos agora para visualiza\u00e7\u00e3o de dados com o pandas. Os m\u00e9todos de visualiza\u00e7\u00e3o do pandas s\u00e3o constru\u00eddos com base no matplotlib para explora\u00e7\u00e3o r\u00e1pida dos dados. Para se ter mais liberdade no conte\u00fado e possibilidades de visualiza\u00e7\u00e3o se recomenda usar diretamente o matplotlib ou ainda, para visualiza\u00e7\u00e3o estat\u00edstica, o seaborn. Nesta introdu\u00e7\u00e3o tratarei apenas dos m\u00e9todos de visualiza\u00e7\u00e3o inclu\u00eddos no pandas, que por outro lado, oferece uma sintaxe bastante simples para realizar a tarefa.\n\nComecemos verificando que tanto Series como DataFrame possuem um m\u00e9todo\n.plot()\n\nque tamb\u00e9m \u00e9 um atributo e pode ser encadeado para gerar visualiza\u00e7\u00e3o de diversos tipos, como histograma, \u00e1rea, pizza e dispers\u00e3o, com respectivamente\n.hist()\n\n,\n.area()\n\n,\n.pie()\n\ne\n.scatter()\n\n, al\u00e9m de v\u00e1rios outros.\n\nVamos verificar a distribui\u00e7\u00e3o dos pre\u00e7os usando o encadeamento\n.plot.hist()\n\n, o eixo x, que \u00e9 o pre\u00e7o, est\u00e1 numa escala de *10^7, como mostrado na imagem:\n\ndf[\"preco\"].plot.hist()\n\nPor padr\u00e3o esse m\u00e9todo usa 10 bins, ou seja, divide os dados em 10 partes, mas \u00e9 claro que podemos especificar um valor para a plotagem. Abaixo, al\u00e9m de especificar a quantidade de bins, tamb\u00e9m especifiquei a cor das bordas como preta, que por padr\u00e3o \u00e9 transparente.\n\ndf[\"preco\"].plot.hist(bins=30, edgecolor='black')\n\nPodemos usar os valores de contagem de cada bairro como exemplo de dado para um plot tanto de barras verticais quando de barras horizontais, para verificar visualmente esses dados:\n\ndf[\"bairro\"].value_counts().plot.bar()\n\ndf[\"bairro\"].value_counts().plot.barh()\n\nOs m\u00e9todos s\u00e3o flex\u00edveis o suficiente para aceitarem argumentos como um t\u00edtulo para a imagem:\n\ndf[\"bairro\"].value_counts().plot.barh(title=\"N\u00famero de apartamentos\")\n\nUm gr\u00e1fico de dispers\u00e3o usando um DataFrame pode ser usado especificando-se quais colunas usar como dados no eixo x e y:\n\ndf.plot.scatter(x='preco', y='area')\n\nPara fins est\u00e9ticos, o matplotlib fornece uma s\u00e9rie de styles diferentes que podem ser usados, um deles \u00e9 o ggplot\n\nplt.style.use('ggplot')\n\nAgora este estilo ser\u00e1 usado em todas as imagens geradas ap\u00f3s essa linha\n\ndf.plot.scatter(x='pm2', y='area')\n\nA lista de estilos dispon\u00edveis pode ser vista atrav\u00e9s de um m\u00e9todo pr\u00f3prio\n\nplt.style.available['bmh',\n\n'Solarize_Light2',\n\n'seaborn-talk',\n\n'seaborn-bright',\n\n'seaborn-white',\n\n'seaborn-pastel',\n\n'seaborn-ticks',\n\n'seaborn-dark-palette',\n\n'seaborn',\n\n'tableau-colorblind10',\n\n'seaborn-deep',\n\n'classic',\n\n'seaborn-dark',\n\n'grayscale',\n\n'seaborn-paper',\n\n'fivethirtyeight',\n\n'seaborn-muted',\n\n'_classic_test',\n\n'seaborn-poster',\n\n'seaborn-notebook',\n\n'seaborn-darkgrid',\n\n'seaborn-colorblind',\n\n'dark_background',\n\n'seaborn-whitegrid',\n\n'ggplot',\n\n'fast']\n\nA coluna de quartos diz quantos quartos tem um determinado apartamento, tamb\u00e9m se pode ver a contagem e distribui\u00e7\u00e3o usando outros m\u00e9todos de plotagem oferecidos pelo pandas:\n\ndf[\"quartos\"].value_counts().plot.pie()\n\nUma coisa a se notar do gr\u00e1fico de scatter \u00e9 a polui\u00e7\u00e3o causada pela enorme quantidade de dados agrupadas num dos cantos do gr\u00e1fico, al\u00e9m de podermos diminuir o tamanho dos pontos passando o argumento\ns\n\nao m\u00e9todo\n.scatter\n\npodemos tamb\u00e9m usar um m\u00e9todo do pandas que cria uma amostragem aleat\u00f3ria dos dados.\n\nO\n.sample\n\npode receber tanto um argumento\nfrac\n\n, que determina uma fra\u00e7\u00e3o dos itens que o m\u00e9todo retornar\u00e1 (no caso abaixo, 10%), ou\nn\n\n, que determina um valor absoluto de itens.\n\ndf.plot.scatter(x='preco', y='area', s=.5)\n\ndf.sample(frac=.1).plot.scatter(x='preco', y='area')\n\nFinalmente, a tarefa de salvar seu DataFrame externamente para um formato espec\u00edfico \u00e9 feita com a mesma simplicidade que a leitura de dados \u00e9 feita no pandas, pode-se usar, por exemplo, o m\u00e9todo\nto_csv\n\n, e o arquivo ser\u00e1 criado com os dados do DataFrame:\n\ndf = pd.DataFrame({'Aluno' : [\"Wilfred\", \"Abbie\", \"Harry\", \"Julia\", \"Carrie\"],\n\n'Faltas' : [3,4,2,1,4],\n\n'Prova' : [2,7,5,10,6],\n\n'Semin\u00e1rio': [8.5,7.5,9.0,7.5,8.0]})\n\ndf.to_csv(\"aulas.csv\")pd.read_csv(\"aulas.csv\")\n\nCom o que foi abordado nesta introdu\u00e7\u00e3o voc\u00ea j\u00e1 deve estar apto a fazer explora\u00e7\u00e3o e manipula\u00e7\u00e3o b\u00e1sica de dados com o pandas, para aprofundar mais aqui v\u00e3o algumas refer\u00eancias:\n\n* Documenta\u00e7\u00e3o oficial\n* Colet\u00e2nea de notebooks Jupyter que abordam profundamente v\u00e1rias ferramentas e casos de uso do Pandas\n* Exerc\u00edcios de Pandas com solu\u00e7\u00f5es, separados por temas\n\nCurtiu esse post? N\u00e3o deixe de compartilhar com seus amigos! Tamb\u00e9m n\u00e3o se esque\u00e7a de se inscrever na nossa newsletter no www.datahackers.com.br! Abra\u00e7o e at\u00e9 a pr\u00f3xima! o/\n\nData Hackers\n\nBlog oficial da comunidade Data Hackers\n\nFollow\n\n1.2K\n\n8\n\n* Python\n* Pandas\n* Jupyter\n* Tutorial\n* Data Science\n\n1.2K claps\n\n1.2K claps\n\n8 responses\n\nWritten by\n\nVin\u00edcius Figueiredo\n\nFollow\n\nFollow\n\nData Hackers\n\nFollow\n\nBlog oficial da comunidade Data Hackers\n\nFollow\n\nWritten by\n\nVin\u00edcius Figueiredo\n\nFollow\n\nData Hackers\n\nFollow\n\nBlog oficial da comunidade Data Hackers\n\nMore From Medium\n\nA magia dos pipelines\n\nRicardo Pinto in Data Hackers\n\nCriando uma cultura data-driven na XP Inc.\u200a\u2014\u200aData Hackers Podcast 28\n\nPaulo Vasconcellos in Data Hackers\n\nO que aprendi no meu primeiro emprego na \u00e1rea de dados\n\nVin\u00edcius Galv\u00e3o in Data Hackers\n\n6 dicas sobre Express\u00f5es Regulares em Python\n\nGustavo Santos in Data Hackers\n\nConstruindo a melhor \u201cfila\u201d para a matriz confus\u00e3o\n\nRicardo Pinto in Data Hackers\n\nEu li 3942 textos da New Order! Parte01\u200a\u2014\u200aTags\n\nGiovani Ferreira in Data Hackers\n\nMachine Learning para Avalia\u00e7\u00e3o de Risco de Cr\u00e9dito\n\nOt\u00e1vio Sim\u00f5es Silveira in Data Hackers\n\nComo Python me Ajudou a Comprar um Carro\n\nMatheos Pires in Data Hackers\n\nDiscover Medium\n\nWelcome to a place where words matter. On Medium, smart voices and original ideas take center stage - with no ads in sight. Watch\n\nMake Medium yours\n\nFollow all the topics you care about, and we\u2019ll deliver the best stories for you to your homepage and inbox. Explore\n\nBecome a member\n\nGet unlimited access to the best stories on Medium \u2014 and support writers while you\u2019re at it. Just $5/month. Upgrade\n\nAbout\n\nHelp\n\nLegal\n\nGet the Medium app",
    "type": "article",
    "url": "https://medium.com/data-hackers/uma-introdu%C3%A7%C3%A3o-simples-ao-pandas-1e15eea37fa1"
}